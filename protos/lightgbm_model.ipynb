{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# LightGBM による不動産価格予測モデル\n",
    "\n",
    "## 目的\n",
    "- リーケージを防止した特徴量エンジニアリング\n",
    "- クロスバリデーションによるモデル検証\n",
    "- ハイパーパラメータチューニング\n",
    "- 特徴量重要度の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォント設定\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Hiragino Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元データを読み込み（特徴量エンジニアリングをCV内で実施するため）\n",
    "train = pd.read_csv(\"../input/estyle-community-competition-2025/train.csv\")\n",
    "test = pd.read_csv(\"../input/estyle-community-competition-2025/test.csv\")\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# ターゲット変数を分離\n",
    "target = train['TradePrice'].copy()\n",
    "train_ids = train['Id'].copy()\n",
    "test_ids = test['Id'].copy()\n",
    "\n",
    "# 対数変換したターゲット（RMSLE評価のため）\n",
    "target_log = np.log1p(target)\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(target.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## リーケージ防止を考慮した特徴量エンジニアリング関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, is_train=True, train_target=None, fold_stats=None):\n",
    "    \"\"\"\n",
    "    リーケージを防止しながら特徴量を作成する関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        入力データ\n",
    "    is_train : bool\n",
    "        訓練データかどうか\n",
    "    train_target : Series\n",
    "        訓練データのターゲット（ターゲットエンコーディング用）\n",
    "    fold_stats : dict\n",
    "        Fold内で計算した統計量（テストデータ用）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_processed : DataFrame\n",
    "        処理済みデータ\n",
    "    fold_stats : dict\n",
    "        計算した統計量（次のFoldやテストデータで使用）\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 統計量の辞書を初期化\n",
    "    if fold_stats is None:\n",
    "        fold_stats = {}\n",
    "    \n",
    "    # ========== 欠損フラグの作成 ==========\n",
    "    df['HasBuilding'] = df['TotalFloorArea'].notnull().astype(int)\n",
    "    df['HasFloorPlan'] = df['FloorPlan'].notnull().astype(int)\n",
    "    df['HasStructure'] = df['Structure'].notnull().astype(int)\n",
    "    df['HasBuildingYear'] = df['BuildingYear'].notnull().astype(int)\n",
    "    df['HasRoadAccess'] = df['Breadth'].notnull().astype(int)\n",
    "    df['HasRoadClassification'] = df['Classification'].notnull().astype(int)\n",
    "    df['HasFrontage'] = df['Frontage'].notnull().astype(int)\n",
    "    df['HasLandShape'] = df['LandShape'].notnull().astype(int)\n",
    "    df['HasDirection'] = df['Direction'].notnull().astype(int)\n",
    "    df['HasStation'] = df['NearestStation'].notnull().astype(int)\n",
    "    df['HasRemarks'] = df['Remarks'].notnull().astype(int)\n",
    "    \n",
    "    # ========== 欠損値の補完 ==========\n",
    "    # 駅情報\n",
    "    df['NearestStation'] = df['NearestStation'].fillna('No Station')\n",
    "    \n",
    "    # MinTimeToNearestStation: Type別の中央値で補完\n",
    "    if 'MinTime_by_Type' not in fold_stats:\n",
    "        fold_stats['MinTime_by_Type'] = df.groupby('Type')['MinTimeToNearestStation'].median().to_dict()\n",
    "        fold_stats['MinTime_global'] = df['MinTimeToNearestStation'].median()\n",
    "    \n",
    "    df['MinTimeToNearestStation'] = df.apply(\n",
    "        lambda row: fold_stats['MinTime_by_Type'].get(row['Type'], fold_stats['MinTime_global']) \n",
    "        if pd.isna(row['MinTimeToNearestStation']) else row['MinTimeToNearestStation'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 冗長な列を削除\n",
    "    df = df.drop(['MaxTimeToNearestStation', 'TimeToNearestStation'], axis=1, errors='ignore')\n",
    "    \n",
    "    # 地域情報\n",
    "    df['Region'] = df['Region'].fillna('Unknown')\n",
    "    \n",
    "    # 建物情報\n",
    "    df['FloorPlan'] = df['FloorPlan'].fillna('No Building')\n",
    "    df['TotalFloorArea'] = df['TotalFloorArea'].fillna(0)\n",
    "    df['BuildingYear'] = df['BuildingYear'].fillna(0)\n",
    "    df['Structure'] = df['Structure'].fillna('No Building')\n",
    "    df['Use'] = df['Use'].fillna('Vacant Land')\n",
    "    df['Renovation'] = df['Renovation'].fillna('Unknown')\n",
    "    df = df.drop('Purpose', axis=1, errors='ignore')\n",
    "    \n",
    "    # 土地情報\n",
    "    df['LandShape'] = df['LandShape'].fillna('Unknown')\n",
    "    df['Direction'] = df['Direction'].fillna('Unknown')\n",
    "    \n",
    "    # Frontage: Type別の中央値で補完\n",
    "    if 'Frontage_by_Type' not in fold_stats:\n",
    "        fold_stats['Frontage_by_Type'] = df.groupby('Type')['Frontage'].median().to_dict()\n",
    "        fold_stats['Frontage_global'] = df['Frontage'].median()\n",
    "    \n",
    "    df['Frontage'] = df.apply(\n",
    "        lambda row: fold_stats['Frontage_by_Type'].get(row['Type'], fold_stats['Frontage_global'])\n",
    "        if pd.isna(row['Frontage']) else row['Frontage'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 道路情報\n",
    "    df['Classification'] = df['Classification'].fillna('No Road')\n",
    "    df['Breadth'] = df['Breadth'].fillna(0)\n",
    "    \n",
    "    # 都市計画情報\n",
    "    df['CityPlanning'] = df['CityPlanning'].fillna('Outside City Planning')\n",
    "    \n",
    "    # CoverageRatio, FloorAreaRatio: Type別の中央値で補完\n",
    "    for col in ['CoverageRatio', 'FloorAreaRatio']:\n",
    "        if f'{col}_by_Type' not in fold_stats:\n",
    "            fold_stats[f'{col}_by_Type'] = df.groupby('Type')[col].median().to_dict()\n",
    "            fold_stats[f'{col}_global'] = df[col].median()\n",
    "        \n",
    "        df[col] = df.apply(\n",
    "            lambda row: fold_stats[f'{col}_by_Type'].get(row['Type'], fold_stats[f'{col}_global'])\n",
    "            if pd.isna(row[col]) else row[col],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # その他\n",
    "    df['DistrictName'] = df['DistrictName'].fillna('Unknown')\n",
    "    df = df.drop('Remarks', axis=1, errors='ignore')\n",
    "    \n",
    "    # ========== 派生特徴量の作成 ==========\n",
    "    # 欠損パターン集約\n",
    "    df['MissingBuildingInfo'] = (\n",
    "        (1 - df['HasFloorPlan']) + \n",
    "        (1 - df['HasBuilding']) + \n",
    "        (1 - df['HasBuildingYear']) + \n",
    "        (1 - df['HasStructure'])\n",
    "    )\n",
    "    \n",
    "    df['MissingRoadInfo'] = (\n",
    "        (1 - df['HasRoadAccess']) + \n",
    "        (1 - df['HasRoadClassification']) + \n",
    "        (1 - df['HasFrontage']) + \n",
    "        (1 - df['HasDirection'])\n",
    "    )\n",
    "    \n",
    "    # 築年数\n",
    "    df['BuildingAge'] = df['Year'] - df['BuildingYear']\n",
    "    df.loc[df['BuildingYear'] == 0, 'BuildingAge'] = -1\n",
    "    \n",
    "    # 面積関連特徴\n",
    "    df['FloorAreaRatioActual'] = df['TotalFloorArea'] / df['Area']\n",
    "    df['FloorAreaRatioActual'] = df['FloorAreaRatioActual'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    df['FloorAreaRatioUsage'] = 0.0\n",
    "    mask = df['FloorAreaRatio'] > 0\n",
    "    df.loc[mask, 'FloorAreaRatioUsage'] = (\n",
    "        df.loc[mask, 'FloorAreaRatioActual'] / df.loc[mask, 'FloorAreaRatio']\n",
    "    )\n",
    "    \n",
    "    # 四半期ダミー\n",
    "    for q in range(1, 5):\n",
    "        df[f'Quarter_Q{q}'] = (df['Quarter'] == q).astype(int)\n",
    "    \n",
    "    # ========== ターゲットエンコーディング（高カーディナリティ変数） ==========\n",
    "    # リーケージ防止: 訓練データのみでエンコーディング値を計算\n",
    "    high_card_cols = ['NearestStation', 'DistrictName', 'Municipality']\n",
    "    \n",
    "    if is_train and train_target is not None:\n",
    "        for col in high_card_cols:\n",
    "            if col in df.columns:\n",
    "                # 各カテゴリの平均値を計算（対数変換済みターゲット）\n",
    "                target_mean = pd.DataFrame({\n",
    "                    col: df[col],\n",
    "                    'target': train_target\n",
    "                }).groupby(col)['target'].mean()\n",
    "                \n",
    "                fold_stats[f'{col}_target_enc'] = target_mean.to_dict()\n",
    "                fold_stats[f'{col}_global_mean'] = train_target.mean()\n",
    "    \n",
    "    # ターゲットエンコーディング値を適用\n",
    "    for col in high_card_cols:\n",
    "        if col in df.columns and f'{col}_target_enc' in fold_stats:\n",
    "            df[f'{col}_TargetEnc'] = df[col].map(\n",
    "                fold_stats[f'{col}_target_enc']\n",
    "            ).fillna(fold_stats[f'{col}_global_mean'])\n",
    "    \n",
    "    # ========== カテゴリ変数のLabel Encoding ==========\n",
    "    # LightGBM用にカテゴリ変数をそのまま保持（文字列型）\n",
    "    categorical_features = [\n",
    "        'Type', 'Prefecture', 'Region', 'Structure', 'LandShape', \n",
    "        'Direction', 'Classification', 'Renovation', 'CityPlanning',\n",
    "        'NearestStation', 'DistrictName', 'Municipality', 'Use', 'FloorPlan'\n",
    "    ]\n",
    "    \n",
    "    # カテゴリ型に変換\n",
    "    for col in categorical_features:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    \n",
    "    return df, fold_stats, categorical_features\n",
    "\n",
    "print(\"特徴量エンジニアリング関数の定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## RMSLE計算関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Logarithmic Error\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def rmsle_lgb(y_pred, dtrain):\n",
    "    \"\"\"\n",
    "    LightGBM用のRMSLE評価関数\n",
    "    対数変換済みの予測値を元のスケールに戻してRMSLEを計算\n",
    "    \"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    # 対数変換を元に戻す\n",
    "    y_true_original = np.expm1(y_true)\n",
    "    y_pred_original = np.expm1(y_pred)\n",
    "    # 負の値をクリップ\n",
    "    y_pred_original = np.maximum(y_pred_original, 0)\n",
    "    score = rmsle(y_true_original, y_pred_original)\n",
    "    return 'rmsle', score, False\n",
    "\n",
    "print(\"評価関数の定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## クロスバリデーション実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_with_cv(train_df, test_df, target, n_splits=5, seed=42):\n",
    "    \"\"\"\n",
    "    クロスバリデーションを用いた学習と予測\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_df : DataFrame\n",
    "        訓練データ\n",
    "    test_df : DataFrame\n",
    "        テストデータ\n",
    "    target : Series\n",
    "        ターゲット変数（元のスケール）\n",
    "    n_splits : int\n",
    "        Foldの数\n",
    "    seed : int\n",
    "        乱数シード\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    oof_predictions : ndarray\n",
    "        Out-of-fold予測値\n",
    "    test_predictions : ndarray\n",
    "        テストデータの予測値\n",
    "    models : list\n",
    "        学習済みモデルのリスト\n",
    "    feature_importance_df : DataFrame\n",
    "        特徴量重要度\n",
    "    cv_scores : list\n",
    "        各Foldのスコア\n",
    "    train_processed_df : DataFrame\n",
    "        処理済み訓練データ（全Fold分）\n",
    "    test_processed_df : DataFrame\n",
    "        処理済みテストデータ\n",
    "    \"\"\"\n",
    "    # 対数変換したターゲット\n",
    "    target_log = np.log1p(target)\n",
    "    \n",
    "    # KFold設定\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # 予測値を格納する配列\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    test_predictions = np.zeros(len(test_df))\n",
    "    \n",
    "    # モデルと特徴量重要度を格納するリスト\n",
    "    models = []\n",
    "    feature_importance_list = []\n",
    "    \n",
    "    # スコアを格納するリスト\n",
    "    cv_scores = []\n",
    "    \n",
    "    # 処理済みデータフレームを格納（最後のFoldのものを保存）\n",
    "    train_processed_df = None\n",
    "    test_processed_df = None\n",
    "    \n",
    "    # LightGBMのパラメータ\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'random_state': seed,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"クロスバリデーション開始: {n_splits} Folds\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df), 1):\n",
    "        print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
    "        \n",
    "        # 訓練データと検証データに分割\n",
    "        X_train_fold = train_df.iloc[train_idx].copy()\n",
    "        X_val_fold = train_df.iloc[val_idx].copy()\n",
    "        y_train_fold = target_log.iloc[train_idx]\n",
    "        y_val_fold = target_log.iloc[val_idx]\n",
    "        \n",
    "        # Fold内で特徴量エンジニアリング（リーケージ防止）\n",
    "        X_train_processed, fold_stats, cat_features = create_features(\n",
    "            X_train_fold, \n",
    "            is_train=True, \n",
    "            train_target=y_train_fold\n",
    "        )\n",
    "        \n",
    "        X_val_processed, _, _ = create_features(\n",
    "            X_val_fold,\n",
    "            is_train=False,\n",
    "            fold_stats=fold_stats\n",
    "        )\n",
    "        \n",
    "        # 不要なカラムを削除\n",
    "        drop_cols = ['Id', 'TradePrice']\n",
    "        X_train_processed = X_train_processed.drop(drop_cols, axis=1, errors='ignore')\n",
    "        X_val_processed = X_val_processed.drop(drop_cols, axis=1, errors='ignore')\n",
    "        \n",
    "        # カラムの整合性を確認\n",
    "        common_cols = X_train_processed.columns.intersection(X_val_processed.columns)\n",
    "        X_train_processed = X_train_processed[common_cols]\n",
    "        X_val_processed = X_val_processed[common_cols]\n",
    "        \n",
    "        # カテゴリカル特徴のインデックスを取得\n",
    "        cat_features_idx = [X_train_processed.columns.get_loc(col) \n",
    "                           for col in cat_features if col in X_train_processed.columns]\n",
    "        \n",
    "        # LightGBM用のデータセット作成\n",
    "        lgb_train = lgb.Dataset(\n",
    "            X_train_processed, \n",
    "            y_train_fold,\n",
    "            categorical_feature=cat_features_idx\n",
    "        )\n",
    "        lgb_val = lgb.Dataset(\n",
    "            X_val_processed, \n",
    "            y_val_fold,\n",
    "            categorical_feature=cat_features_idx,\n",
    "            reference=lgb_train\n",
    "        )\n",
    "        \n",
    "        # モデル学習\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[lgb_train, lgb_val],\n",
    "            valid_names=['train', 'valid'],\n",
    "            feval=rmsle_lgb,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "                lgb.log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Out-of-fold予測（対数スケール）\n",
    "        oof_pred_log = model.predict(X_val_processed, num_iteration=model.best_iteration)\n",
    "        oof_predictions[val_idx] = oof_pred_log\n",
    "        \n",
    "        # 元のスケールに戻してスコア計算\n",
    "        y_val_original = np.expm1(y_val_fold)\n",
    "        oof_pred_original = np.expm1(oof_pred_log)\n",
    "        oof_pred_original = np.maximum(oof_pred_original, 0)\n",
    "        \n",
    "        fold_score = rmsle(y_val_original, oof_pred_original)\n",
    "        cv_scores.append(fold_score)\n",
    "        print(f\"Fold {fold} RMSLE: {fold_score:.6f}\")\n",
    "        \n",
    "        # テストデータの予測\n",
    "        X_test_processed, _, _ = create_features(\n",
    "            test_df,\n",
    "            is_train=False,\n",
    "            fold_stats=fold_stats\n",
    "        )\n",
    "        X_test_processed = X_test_processed.drop(['Id'], axis=1, errors='ignore')\n",
    "        X_test_processed = X_test_processed[common_cols]\n",
    "        \n",
    "        test_pred_log = model.predict(X_test_processed, num_iteration=model.best_iteration)\n",
    "        test_predictions += test_pred_log / n_splits\n",
    "        \n",
    "        # モデルと特徴量重要度を保存\n",
    "        models.append(model)\n",
    "        \n",
    "        fold_importance = pd.DataFrame({\n",
    "            'feature': X_train_processed.columns,\n",
    "            'importance': model.feature_importance(importance_type='gain'),\n",
    "            'fold': fold\n",
    "        })\n",
    "        feature_importance_list.append(fold_importance)\n",
    "        \n",
    "        # 最後のFoldで処理済みデータフレームを保存\n",
    "        if fold == n_splits:\n",
    "            # 全訓練データを処理（最後のfold_statsを使用）\n",
    "            train_processed_full, _, _ = create_features(\n",
    "                train_df,\n",
    "                is_train=False,\n",
    "                fold_stats=fold_stats\n",
    "            )\n",
    "            train_processed_df = train_processed_full.drop(['Id', 'TradePrice'], axis=1, errors='ignore')\n",
    "            train_processed_df = train_processed_df[common_cols]\n",
    "            \n",
    "            # テストデータも保存\n",
    "            test_processed_df = X_test_processed.copy()\n",
    "    \n",
    "    # 全体のCVスコア\n",
    "    oof_pred_original = np.expm1(oof_predictions)\n",
    "    oof_pred_original = np.maximum(oof_pred_original, 0)\n",
    "    overall_score = rmsle(target, oof_pred_original)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"クロスバリデーション結果\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"各Foldのスコア: {[f'{s:.6f}' for s in cv_scores]}\")\n",
    "    print(f\"平均スコア: {np.mean(cv_scores):.6f} (+/- {np.std(cv_scores):.6f})\")\n",
    "    print(f\"Overall OOF Score: {overall_score:.6f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # 特徴量重要度の集約\n",
    "    feature_importance_df = pd.concat(feature_importance_list, axis=0)\n",
    "    \n",
    "    return oof_predictions, test_predictions, models, feature_importance_df, cv_scores, train_processed_df, test_processed_df\n",
    "\n",
    "print(\"クロスバリデーション関数の定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## モデルの学習と予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションで学習\n",
    "oof_preds, test_preds, trained_models, feature_importance, cv_scores, train_processed, test_processed = train_and_predict_with_cv(\n",
    "    train, \n",
    "    test, \n",
    "    target,\n",
    "    n_splits=5,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. 処理済みデータの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理済みデータフレームの確認\n",
    "print(f\"訓練データ処理済み: {train_processed.shape}\")\n",
    "print(f\"テストデータ処理済み: {test_processed.shape}\")\n",
    "\n",
    "# CSVファイルとして保存\n",
    "import os\n",
    "output_dir = \"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_processed.to_csv(f\"{output_dir}/train_features_processed.csv\", index=False)\n",
    "test_processed.to_csv(f\"{output_dir}/test_features_processed.csv\", index=False)\n",
    "\n",
    "print(f\"\\n処理済みデータを保存しました:\")\n",
    "print(f\"- {output_dir}/train_features_processed.csv\")\n",
    "print(f\"- {output_dir}/test_features_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 特徴量重要度の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均重要度を計算\n",
    "importance_grouped = feature_importance.groupby('feature')['importance'].agg(['mean', 'std']).reset_index()\n",
    "importance_grouped = importance_grouped.sort_values('mean', ascending=False)\n",
    "\n",
    "# 上位30個の特徴量を可視化\n",
    "top_n = 30\n",
    "top_features = importance_grouped.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.barh(range(len(top_features)), top_features['mean'], xerr=top_features['std'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance (Gain)')\n",
    "plt.title(f'Top {top_n} Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/feature_importance_lightgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Top 30 Feature Importance ===\")\n",
    "print(top_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 予測結果の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF予測を元のスケールに変換\n",
    "oof_preds_original = np.expm1(oof_preds)\n",
    "oof_preds_original = np.maximum(oof_preds_original, 0)\n",
    "\n",
    "# 実測値 vs 予測値のプロット\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 散布図\n",
    "axes[0].scatter(target, oof_preds_original, alpha=0.3, s=1)\n",
    "axes[0].plot([target.min(), target.max()], [target.min(), target.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Price (Yen)')\n",
    "axes[0].set_ylabel('Predicted Price (Yen)')\n",
    "axes[0].set_title('Actual vs Predicted (OOF)')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# 残差プロット\n",
    "residuals = target - oof_preds_original\n",
    "axes[1].scatter(oof_preds_original, residuals, alpha=0.3, s=1)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Price (Yen)')\n",
    "axes[1].set_ylabel('Residuals (Yen)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/prediction_analysis_lightgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 予測値の統計\n",
    "print(\"\\n=== OOF Prediction Statistics ===\")\n",
    "print(pd.Series(oof_preds_original).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## サブミッションファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト予測を元のスケールに変換\n",
    "test_preds_original = np.expm1(test_preds)\n",
    "test_preds_original = np.maximum(test_preds_original, 0)\n",
    "\n",
    "# サブミッションファイル作成\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'TradePrice': test_preds_original\n",
    "})\n",
    "\n",
    "# 保存\n",
    "submission.to_csv('../output/submission_lightgbm.csv', index=False)\n",
    "\n",
    "print(\"\\n=== Submission File Created ===\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(submission['TradePrice'].describe())\n",
    "print(f\"\\nFile saved: ../output/submission_lightgbm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## モデルパフォーマンスのサマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVスコアの可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(cv_scores) + 1), cv_scores, alpha=0.7, color='steelblue')\n",
    "plt.axhline(y=np.mean(cv_scores), color='red', linestyle='--', label=f'Mean: {np.mean(cv_scores):.6f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.title('Cross-Validation Scores by Fold')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/cv_scores_lightgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"モデルパフォーマンスサマリー\")\n",
    "print(\"=\"*60)\n",
    "print(f\"モデル: LightGBM\")\n",
    "print(f\"特徴量数: {len(importance_grouped)}\")\n",
    "print(f\"CVフォールド数: {len(cv_scores)}\")\n",
    "print(f\"\\nクロスバリデーションスコア:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.6f}\")\n",
    "print(f\"\\n平均RMSLE: {np.mean(cv_scores):.6f}\")\n",
    "print(f\"標準偏差: {np.std(cv_scores):.6f}\")\n",
    "print(f\"Overall OOF RMSLE: {rmsle(target, oof_preds_original):.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
