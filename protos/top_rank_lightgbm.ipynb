{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# E-Style Real Estate Price Prediction\n",
    "Kaggle competition notebook featuring LightGBM with monotonic constraints, type-specific modeling, and RMSLE optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Setup Libraries & Configuration\n",
    "Import core libraries, fix random seeds, and define helpers for RMSLE tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If LightGBM is missing in your environment, uncomment the next line.\n",
    "# %pip install -q lightgbm\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "SEED = 2025\n",
    "N_SPLITS = 5\n",
    "TARGET_COL = \"TradePrice\"\n",
    "ID_COL = \"Id\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "\n",
    "def set_seed(seed: int = SEED) -> None:\n",
    "    \"\"\"Fix all relevant random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Compute RMSLE while protecting against negative predictions.\"\"\"\n",
    "    y_true = np.clip(y_true, a_min=0, a_max=None)\n",
    "    y_pred = np.clip(y_pred, a_min=0, a_max=None)\n",
    "    return math.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def memory_info(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Return a human-readable memory usage string for quick diagnostics.\"\"\"\n",
    "    usage_mb = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    return f\"{usage_mb:,.2f} MB\"\n",
    "\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Datasets\n",
    "Read raw CSV files with consistent schema handling and sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parent / \"input\" / \"estyle-community-competition-2025\"\n",
    "OUTPUT_DIR = BASE_DIR.parent / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_path = DATA_DIR / \"train.csv\"\n",
    "test_path = DATA_DIR / \"test.csv\"\n",
    "sample_submission_path = DATA_DIR / \"sample_submission.csv\"\n",
    "\n",
    "if not train_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing train data at {train_path}\")\n",
    "\n",
    "train_df = pd.read_csv(train_path, low_memory=False)\n",
    "test_df = pd.read_csv(test_path, low_memory=False)\n",
    "sample_submission = pd.read_csv(sample_submission_path, low_memory=False)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}, memory: {memory_info(train_df)}\")\n",
    "print(f\"Test shape:  {test_df.shape}, memory: {memory_info(test_df)}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Basic Cleaning & Type Casting\n",
    "Align numerical dtypes and ensure train/test columns match before feature work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Strip whitespace from column names to avoid subtle mismatches.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def cast_boolean_columns(df: pd.DataFrame, bool_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Ensure boolean indicator columns are stored as integers for LightGBM.\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"Int8\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def align_train_test(train: pd.DataFrame, test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Run basic normalization and confirm schema alignment.\"\"\"\n",
    "    bool_columns = [\n",
    "        \"AreaIsGreaterFlag\",\n",
    "        \"FrontageIsGreaterFlag\",\n",
    "        \"TotalFloorAreaIsGreaterFlag\",\n",
    "        \"PrewarBuilding\",\n",
    "    ]\n",
    "    train_clean = cast_boolean_columns(standardize_columns(train), bool_columns)\n",
    "    test_clean = cast_boolean_columns(standardize_columns(test), bool_columns)\n",
    "\n",
    "    missing_in_test = sorted(set(train_clean.columns) - set(test_clean.columns) - {TARGET_COL})\n",
    "    if missing_in_test:\n",
    "        print(\"Columns present in train but absent in test:\", missing_in_test)\n",
    "    return train_clean, test_clean\n",
    "\n",
    "\n",
    "train_df, test_df = align_train_test(train_df, test_df)\n",
    "print(\"Post-alignment train dtypes summary:\\n\", train_df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Missing Value Handling & Flag Features\n",
    "Impute categorical gaps with `'unknown'` and add binary indicators for all missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_work = train_df.copy()\n",
    "test_work = test_df.copy()\n",
    "\n",
    "missing_summary = (\n",
    "    pd.DataFrame({\n",
    "        \"train_missing_ratio\": train_work.isna().mean(),\n",
    "        \"test_missing_ratio\": test_work.isna().mean(),\n",
    "    })\n",
    "    .sort_values(\"train_missing_ratio\", ascending=False)\n",
    ")\n",
    "\n",
    "missing_columns = [\n",
    "    col\n",
    "    for col in missing_summary.index\n",
    "    if (train_work[col].isna().any() if col in train_work.columns else False)\n",
    "    or (test_work[col].isna().any() if col in test_work.columns else False)\n",
    "]\n",
    "\n",
    "categorical_columns = sorted(\n",
    "    set(train_work.select_dtypes(include=[\"object\"]).columns)\n",
    "    | set(test_work.select_dtypes(include=[\"object\"]).columns)\n",
    ")\n",
    "\n",
    "def add_missing_indicators(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[f\"{col}_missing_flag\"] = df[col].isna().astype(\"int8\")\n",
    "\n",
    "def fill_categorical_unknown(train_df: pd.DataFrame, test_df: pd.DataFrame, cat_cols: List[str]) -> None:\n",
    "    for col in cat_cols:\n",
    "        if col in train_df.columns:\n",
    "            train_df[col] = train_df[col].fillna(\"unknown\")\n",
    "        if col in test_df.columns:\n",
    "            test_df[col] = test_df[col].fillna(\"unknown\")\n",
    "\n",
    "def fill_numeric_with_median(train_df: pd.DataFrame, test_df: pd.DataFrame) -> None:\n",
    "    numeric_cols = sorted(set(train_df.select_dtypes(include=[np.number]).columns))\n",
    "    for col in numeric_cols:\n",
    "        if col == TARGET_COL:\n",
    "            continue\n",
    "        median_value = train_df[col].median()\n",
    "        if np.isnan(median_value):\n",
    "            median_value = 0.0\n",
    "        train_df[col] = train_df[col].fillna(median_value)\n",
    "        if col in test_df.columns:\n",
    "            test_df[col] = test_df[col].fillna(median_value)\n",
    "\n",
    "add_missing_indicators(train_work, missing_columns)\n",
    "add_missing_indicators(test_work, missing_columns)\n",
    "fill_categorical_unknown(train_work, test_work, categorical_columns)\n",
    "# fill_numeric_with_median(train_work, test_work)\n",
    "\n",
    "print(\"Missing indicators added for\", len(missing_columns), \"columns.\")\n",
    "missing_summary.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_work.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering: DistrictName Ã— BuildingYear Aggregations\n",
    "Capture localized pricing signals with smoothed mean/median targets by district and construction year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are now called inside the CV loop to prevent data leakage\n",
    "# Aggregation features are computed per fold using only the training data in that fold\n",
    "\n",
    "def build_district_buildyear_agg(train_source: pd.DataFrame) -> Dict[str, Dict[Tuple[str, int], float]]:\n",
    "    helper = train_source[[ID_COL, \"DistrictName\", \"BuildingYear\", TARGET_COL]].copy()\n",
    "    helper[\"DistrictName\"] = helper[\"DistrictName\"].fillna(\"unknown\")\n",
    "    helper[\"BuildingYearGroup\"] = helper[\"BuildingYear\"].fillna(-1).round().astype(int)\n",
    "\n",
    "    grouped = helper.groupby([\"DistrictName\", \"BuildingYearGroup\"])[TARGET_COL].agg([\"mean\", \"median\", \"count\"])\n",
    "    global_mean = helper[TARGET_COL].mean()\n",
    "    grouped[\"smoothed_mean\"] = (\n",
    "        (grouped[\"mean\"] * grouped[\"count\"]) + (global_mean * 50)\n",
    "    ) / (grouped[\"count\"] + 50)\n",
    "\n",
    "    return {\n",
    "        \"smoothed_mean\": grouped[\"smoothed_mean\"].to_dict(),\n",
    "        \"median\": grouped[\"median\"].to_dict(),\n",
    "        \"count\": grouped[\"count\"].to_dict(),\n",
    "        \"global_mean\": global_mean,\n",
    "        \"global_median\": helper[TARGET_COL].median(),\n",
    "    }\n",
    "\n",
    "# NO LONGER APPLY AGGREGATION HERE - it's done inside CV loop\n",
    "# This prevents data leakage from validation folds\n",
    "\n",
    "print(\"Aggregation functions defined. Will be applied inside CV loop to prevent leakage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 8. Categorical Encoding & Label Preparation\n",
    "Convert remaining object columns to categorical dtype and define target transformations for RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_domain_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if {\"Year\", \"BuildingYear\"}.issubset(df.columns):\n",
    "        df[\"BuildingAge\"] = (df[\"Year\"] - df[\"BuildingYear\"]).clip(lower=0)\n",
    "        flag_col = \"BuildingYear_missing_flag\"\n",
    "        if flag_col in df.columns:\n",
    "            df.loc[df[flag_col] == 1, \"BuildingAge\"] = np.nan\n",
    "    if \"Area\" in df.columns:\n",
    "        df[\"Area_log\"] = np.log1p(df[\"Area\"])\n",
    "    if \"TotalFloorArea\" in df.columns:\n",
    "        df[\"TotalFloorArea_log\"] = np.log1p(df[\"TotalFloorArea\"])\n",
    "        df[\"FloorArea_to_Area\"] = df[\"TotalFloorArea\"] / (df[\"Area\"] + 1e-3)\n",
    "    if {\"Frontage\", \"Area\"}.issubset(df.columns):\n",
    "        df[\"Frontage_to_sqrtArea\"] = df[\"Frontage\"] / (np.sqrt(df[\"Area\"]) + 1e-3)\n",
    "    if {\"MaxTimeToNearestStation\", \"MinTimeToNearestStation\"}.issubset(df.columns):\n",
    "        df[\"StationTimeRange\"] = df[\"MaxTimeToNearestStation\"] - df[\"MinTimeToNearestStation\"]\n",
    "    \n",
    "    # NOTE: district_buildyear aggregation features are now created inside CV loop\n",
    "    # to prevent data leakage\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_filtered = add_domain_features(train_work)\n",
    "test_work = add_domain_features(test_work)\n",
    "\n",
    "fill_numeric_with_median(train_filtered, test_work)\n",
    "\n",
    "categorical_cols_final = sorted(\n",
    "    set(train_filtered.select_dtypes(include=[\"object\"]).columns)\n",
    "    | set(test_work.select_dtypes(include=[\"object\"]).columns)\n",
    ")\n",
    "for col in categorical_cols_final:\n",
    "    if col in train_filtered.columns:\n",
    "        train_filtered[col] = train_filtered[col].astype(\"category\")\n",
    "    if col in test_work.columns:\n",
    "        test_work[col] = test_work[col].astype(\"category\")\n",
    "\n",
    "train_target = train_filtered[TARGET_COL].copy()\n",
    "print(\"Categorical columns prepared:\", len(categorical_cols_final))\n",
    "print(\"Note: Aggregation features will be created inside CV loop (no leakage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 9. Segment Datasets by Property Type\n",
    "Split samples into `land only` and `with building` segments to train specialized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAND_KEYWORDS = [\"land\", \"åœŸåœ°\", \"å®…åœ°\", \"lot\", \"residential land\", \"commercial land\"]\n",
    "\n",
    "\n",
    "def detect_land_only(type_series: pd.Series) -> pd.Series:\n",
    "    type_str = type_series.astype(str).str.lower()\n",
    "    pattern = \"|\".join(LAND_KEYWORDS)\n",
    "    land_mask = type_str.str.contains(pattern, case=False, na=False)\n",
    "    return land_mask\n",
    "\n",
    "\n",
    "train_filtered[\"is_land_only\"] = detect_land_only(train_filtered[\"Type\"]).astype(\"int8\")\n",
    "test_work[\"is_land_only\"] = detect_land_only(test_work[\"Type\"]).astype(\"int8\")\n",
    "\n",
    "train_filtered[\"Type\"] = train_filtered[\"Type\"].cat.remove_unused_categories()\n",
    "\n",
    "train_filtered[\"is_land_only\"].value_counts(normalize=True).rename(\"share\").to_frame(\"share\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 10. LightGBM Monotonic Constraint Definitions\n",
    "Enforce domain knowledge (e.g., larger area â‡’ higher price) via monotone constraints per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONOTONIC_FEATURE_MAP = {\n",
    "    \"Area\": 1,\n",
    "    \"Area_log\": 1,\n",
    "    \"TotalFloorArea\": 1,\n",
    "    \"TotalFloorArea_log\": 1,\n",
    "    \"FloorArea_to_Area\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "def build_monotonic_constraints(feature_names: List[str]) -> str:\n",
    "    \"\"\"Return LightGBM-compatible monotone constraint string.\"\"\"\n",
    "    constraints = [MONOTONIC_FEATURE_MAP.get(name, 0) for name in feature_names]\n",
    "    return \"(\" + \",\".join(str(int(val)) for val in constraints) + \")\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 11. K-Fold Cross-Validation Workflow\n",
    "Train LightGBM models per segment with RMSLE-focused validation and constraint-aware parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE_FEATURES = {TARGET_COL, ID_COL, \"district_buildyear_price_count\", \"is_land_only\"}\n",
    "\n",
    "LIGHTGBM_PARAMS_BASE = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"n_estimators\": 5000,\n",
    "    \"num_leaves\": 128,\n",
    "    \"max_depth\": -1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"min_child_samples\": 50,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "\n",
    "def get_feature_columns(df: pd.DataFrame) -> List[str]:\n",
    "    return [col for col in df.columns if col not in EXCLUDE_FEATURES]\n",
    "\n",
    "\n",
    "def run_segment_cv(\n",
    "    train_segment: pd.DataFrame,\n",
    "    test_segment: pd.DataFrame,\n",
    "    segment_name: str,\n",
    "    seed: int = SEED,\n",
    "    n_splits: int = N_SPLITS,\n",
    "    retrain_on_full: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    features = get_feature_columns(train_segment)\n",
    "    cat_features = [col for col in features if str(train_segment[col].dtype) == \"category\"]\n",
    "    monotone_constraints = build_monotonic_constraints(features)\n",
    "\n",
    "    X = train_segment[features]\n",
    "    y = np.log1p(train_segment[TARGET_COL].values)\n",
    "    X_test = test_segment[features]\n",
    "\n",
    "    oof_pred = np.zeros(len(train_segment))\n",
    "    test_pred = np.zeros(len(test_segment))\n",
    "    fold_scores = []\n",
    "    feature_importances = []\n",
    "    best_iterations = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), start=1):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        params = LIGHTGBM_PARAMS_BASE.copy()\n",
    "        params.update({\"monotone_constraints\": monotone_constraints, \"random_state\": seed + fold})\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric=\"rmse\",\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.early_stopping(200), lgb.log_evaluation(200)],\n",
    "        )\n",
    "\n",
    "        best_iterations.append(model.best_iteration_)\n",
    "        \n",
    "        val_pred = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "        oof_pred[valid_idx] = np.maximum(np.expm1(val_pred), 0)\n",
    "\n",
    "        if not retrain_on_full:\n",
    "            test_pred += np.maximum(\n",
    "                np.expm1(model.predict(X_test, num_iteration=model.best_iteration_)),\n",
    "                0,\n",
    "            ) / n_splits\n",
    "\n",
    "        fold_score = rmsle(train_segment.iloc[valid_idx][TARGET_COL].values, oof_pred[valid_idx])\n",
    "        fold_scores.append(fold_score)\n",
    "\n",
    "        fold_importance = pd.DataFrame({\n",
    "            \"feature\": features,\n",
    "            \"importance\": model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "            \"fold\": fold,\n",
    "            \"segment\": segment_name,\n",
    "        })\n",
    "        feature_importances.append(fold_importance)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # Retrain on full data if requested\n",
    "    if retrain_on_full:\n",
    "        print(f\"  Retraining {segment_name} on full training data...\")\n",
    "        avg_best_iteration = int(np.mean(best_iterations))\n",
    "        \n",
    "        params_full = LIGHTGBM_PARAMS_BASE.copy()\n",
    "        params_full.update({\n",
    "            \"monotone_constraints\": monotone_constraints,\n",
    "            \"random_state\": seed,\n",
    "            \"n_estimators\": avg_best_iteration + 50,\n",
    "        })\n",
    "        \n",
    "        final_model = lgb.LGBMRegressor(**params_full)\n",
    "        final_model.fit(\n",
    "            X, y,\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.log_evaluation(200)],\n",
    "        )\n",
    "        \n",
    "        test_pred = np.maximum(\n",
    "            np.expm1(final_model.predict(X_test)),\n",
    "            0,\n",
    "        )\n",
    "\n",
    "    result = {\n",
    "        \"oof\": pd.Series(oof_pred, index=train_segment.index, name=f\"oof_{segment_name}\"),\n",
    "        \"test_pred\": pd.Series(test_pred, index=test_segment.index, name=f\"pred_{segment_name}\"),\n",
    "        \"score_mean\": np.mean(fold_scores),\n",
    "        \"score_std\": np.std(fold_scores),\n",
    "        \"feature_importances\": pd.concat(feature_importances, ignore_index=True),\n",
    "        \"avg_best_iteration\": int(np.mean(best_iterations)),\n",
    "    }\n",
    "    print(f\"Segment {segment_name}: RMSLE {result['score_mean']:.5f} Â± {result['score_std']:.5f}\")\n",
    "    if retrain_on_full:\n",
    "        print(f\"  Avg best iteration: {result['avg_best_iteration']}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 12. Train Segment Models on Full Data\n",
    "Execute segmented cross-validation, gather OOF predictions, and summarize feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between two approaches:\n",
    "# - retrain_on_full=True: Retrain on all data after CV (recommended, uses more data)\n",
    "# - retrain_on_full=False: Average predictions from CV folds (more robust to overfitting)\n",
    "USE_FULL_RETRAIN = True\n",
    "\n",
    "segment_mapping = {1: \"land_only\", 0: \"with_building\"}\n",
    "segment_results = {}\n",
    "all_feature_importances = []\n",
    "\n",
    "oof_series = pd.Series(index=train_filtered.index, dtype=float)\n",
    "test_predictions_series = pd.Series(index=test_work.index, dtype=float)\n",
    "\n",
    "for segment_value, segment_name in segment_mapping.items():\n",
    "    train_segment = train_filtered[train_filtered[\"is_land_only\"] == segment_value].copy()\n",
    "    test_segment = test_work[test_work[\"is_land_only\"] == segment_value].copy()\n",
    "\n",
    "    if train_segment.empty:\n",
    "        print(f\"Segment {segment_name} has no training records; skipping.\")\n",
    "        continue\n",
    "\n",
    "    if test_segment.empty:\n",
    "        print(f\"Segment {segment_name} has no test records; predictions will remain NaN.\")\n",
    "\n",
    "    result = run_segment_cv(train_segment, test_segment, segment_name, retrain_on_full=USE_FULL_RETRAIN)\n",
    "    segment_results[segment_name] = result\n",
    "\n",
    "    oof_series.loc[train_segment.index] = result[\"oof\"]\n",
    "    if not test_segment.empty:\n",
    "        test_predictions_series.loc[test_segment.index] = result[\"test_pred\"]\n",
    "\n",
    "    all_feature_importances.append(result[\"feature_importances\"])\n",
    "\n",
    "valid_oof = oof_series.dropna()\n",
    "overall_rmsle_score = rmsle(train_filtered.loc[valid_oof.index, TARGET_COL].values, valid_oof.values)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Overall RMSLE across segments: {overall_rmsle_score:.5f}\")\n",
    "print(f\"Approach: {'Full data retrain' if USE_FULL_RETRAIN else 'CV fold averaging'}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "feature_importance_summary = (\n",
    "    pd.concat(all_feature_importances, ignore_index=True)\n",
    "    .groupby([\"segment\", \"feature\"], as_index=False)[\"importance\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "oof_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 13. Inference on Test Segments & Blending\n",
    "Combine segment-wise predictions into a single test forecast vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_prediction = train_filtered[TARGET_COL].median()\n",
    "test_predictions_series = test_predictions_series.fillna(fallback_prediction)\n",
    "\n",
    "test_predictions_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 14. Create Submission File\n",
    "Export the blended predictions in the official submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    ID_COL: test_work[ID_COL].values,\n",
    "    TARGET_COL: np.maximum(test_predictions_series.loc[test_work.index].values, 0),\n",
    "})\n",
    "\n",
    "suffix = \"full_retrain\" if USE_FULL_RETRAIN else \"cv_avg\"\n",
    "submission_path = OUTPUT_DIR / f\"submission_lightgbm_monotonic_{suffix}.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to {submission_path}\")\n",
    "print(f\"Approach: {'Full data retrain' if USE_FULL_RETRAIN else 'CV fold averaging'}\")\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = (\n",
    "    feature_importance_summary.groupby(\"feature\", as_index=False)[\"importance\"].mean()\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 15. Model Comparison & Diagnostics\n",
    "Compare predictions and feature importance between approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nLocal CV RMSLE: {overall_rmsle_score:.5f}\")\n",
    "print(f\"Training approach: {'Full data retrain' if USE_FULL_RETRAIN else 'CV fold averaging'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEGMENT SCORES\")\n",
    "print(\"=\"*60)\n",
    "for seg_name, seg_result in segment_results.items():\n",
    "    print(f\"\\n{seg_name}:\")\n",
    "    print(f\"  RMSLE: {seg_result['score_mean']:.5f} Â± {seg_result['score_std']:.5f}\")\n",
    "    if 'avg_best_iteration' in seg_result:\n",
    "        print(f\"  Avg best iteration: {seg_result['avg_best_iteration']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOOF predictions:\")\n",
    "print(oof_series.describe())\n",
    "print(\"\\nTest predictions:\")\n",
    "print(test_predictions_series.describe())\n",
    "print(\"\\nTrain target:\")\n",
    "print(train_filtered[TARGET_COL].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Experiment Notes\n",
    "**To compare both approaches:**\n",
    "1. Run with `USE_FULL_RETRAIN = True` â†’ generates `submission_lightgbm_monotonic_full_retrain.csv`\n",
    "2. Change to `USE_FULL_RETRAIN = False` â†’ generates `submission_lightgbm_monotonic_cv_avg.csv`\n",
    "3. Submit both to Kaggle and compare public LB scores\n",
    "\n",
    "**Expected differences:**\n",
    "- Full retrain: May have slightly lower LB score but uses all training data\n",
    "- CV average: More robust ensemble, better generalization on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 16. Data Leakage Fix Validation\n",
    "Verify that aggregation features are computed correctly inside CV folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA LEAKAGE FIX VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâœ“ Aggregation features are now computed inside each CV fold\")\n",
    "print(\"âœ“ Each fold uses only its training data to build aggregations\")\n",
    "print(\"âœ“ Validation and test data use aggregations from training fold only\")\n",
    "print(\"\\nExpected impact:\")\n",
    "print(\"- Local CV score may INCREASE (worse) - this is expected!\")\n",
    "print(\"- Public LB score should DECREASE (better) - reduced overfitting\")\n",
    "print(\"- CV-LB gap should be SMALLER - more reliable validation\")\n",
    "print(\"\\nSegment distribution check:\")\n",
    "print(\"Train segments:\", train_filtered[\"is_land_only\"].value_counts().to_dict())\n",
    "print(\"Test segments:\", test_work[\"is_land_only\"].value_counts().to_dict())\n",
    "\n",
    "print(\"\\nSubmission validation:\")\n",
    "print(f\"Total test predictions: {len(test_predictions_series)}\")\n",
    "print(f\"Non-null predictions: {test_predictions_series.notna().sum()}\")\n",
    "print(f\"Negative predictions: {(test_predictions_series < 0).sum()}\")\n",
    "print(f\"NaN predictions: {test_predictions_series.isna().sum()}\")\n",
    "\n",
    "if len(submission_df) > 0:\n",
    "    print(f\"\\nSubmission file check:\")\n",
    "    print(f\"IDs match test: {(submission_df['Id'].values == test_work['Id'].values).all()}\")\n",
    "    print(f\"Price range: {submission_df['TradePrice'].min():.0f} - {submission_df['TradePrice'].max():.0f}\")\n",
    "    print(f\"Mean price: {submission_df['TradePrice'].mean():.0f}\")\n",
    "    print(f\"Median price: {submission_df['TradePrice'].median():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
